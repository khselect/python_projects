import streamlit as st
import tempfile
import os
import shutil
import re
import pymupdf4llm 
import time
import mammoth  # docx ë³€í™˜ìš©
import markdownify # html to markdown ìš©
import olefile # hwp ê¸°ì´ˆ ë¶„ì„ìš©

import chromadb 
from chromadb.errors import InternalError as ChromaInternalError

# [ì„¤ì •] í™˜ê²½ ë³€ìˆ˜
os.environ["NO_PROXY"] = "localhost,127.0.0.1"
os.environ["OLLAMA_HOST"] = "http://127.0.0.1:11434"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA


from langchain.prompts import PromptTemplate
from langchain.docstore.document import Document
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter

PERSIST_DIRECTORY = "./chroma_db"

st.set_page_config(page_title="ğŸ›¡ï¸ ì‚¬ë‚´ ê·œì • ë§ˆìŠ¤í„° AI (v3.0)", layout="wide")
st.title("ğŸ›¡ï¸ ì‚¬ë‚´ ê·œì • ë§ˆìŠ¤í„° AI (Word/HWP ì§€ì›)")

# --------------------------------------------------------------------------------
# 1. ë¬¸ì„œ ì „ì²˜ë¦¬ ë¡œì§ (PDF, DOCX, HWP í†µí•©)
# --------------------------------------------------------------------------------
def clean_markdown_text(text):
    text = text.replace("~~", "") 
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text

def convert_docx_to_markdown(docx_path):
    """
    Word(.docx) íŒŒì¼ì„ HTMLë¡œ ë³€í™˜ í›„ ë‹¤ì‹œ Markdownìœ¼ë¡œ ë³€í™˜ (í‘œ êµ¬ì¡° ë³´ì¡´ ìµœì í™”)
    """
    with open(docx_path, "rb") as docx_file:
        # 1. mammothë¥¼ ì‚¬ìš©í•´ docx -> raw html ë³€í™˜
        result = mammoth.convert_to_html(docx_file)
        html = result.value
        messages = result.messages # ê²½ê³  ë©”ì‹œì§€ ë“±
        
    # 2. markdownifyë¥¼ ì‚¬ìš©í•´ html -> markdown ë³€í™˜
    # heading_style="ATX"ëŠ” # í—¤ë” ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©í•˜ê²Œ í•¨
    md_text = markdownify.markdownify(html, heading_style="ATX")
    return md_text

def extract_hwp_text(hwp_path):
    """
    HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (í‘œ êµ¬ì¡°ëŠ” ê¹¨ì§ˆ ìˆ˜ ìˆìŒ - ê¸°ìˆ ì  í•œê³„)
    """
    # Olefileì„ ì´ìš©í•œ ê¸°ì´ˆ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„ (ë³µì¡í•œ í‘œëŠ” ì¸ì‹ ë¶ˆê°€)
    try:
        f = olefile.OleFileIO(hwp_path)
        encoded_text = f.openstream("PrvText").read()
        decoded_text = encoded_text.decode("utf-16le")
        return decoded_text
    except Exception as e:
        return f"[HWP ë³€í™˜ ì˜¤ë¥˜] HWP íŒŒì¼ì€ Word(.docx)ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\nì˜¤ë¥˜ë‚´ìš©: {e}"

def process_file_to_docs(file, source_name):
    # í™•ì¥ì í™•ì¸
    file_ext = os.path.splitext(file.name)[1].lower()
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
        tmp.write(file.getvalue())
        tmp_path = tmp.name

    try:
        # íŒŒì¼ íƒ€ì…ë³„ ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì „ëµ
        if file_ext == ".pdf":
            md_text = pymupdf4llm.to_markdown(tmp_path)
        elif file_ext == ".docx":
            md_text = convert_docx_to_markdown(tmp_path)
        elif file_ext in [".hwp", ".hwpx"]:
            # HWPëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œë˜ë¯€ë¡œ ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°í™”ê°€ ì•½í•  ìˆ˜ ìˆìŒ
            raw_text = extract_hwp_text(tmp_path)
            md_text = clean_markdown_text(raw_text)
            # HWPëŠ” í—¤ë” ì¸ì‹ì´ ì–´ë ¤ìš°ë¯€ë¡œ ì„ì˜ì˜ í—¤ë”ë¥¼ ë¶™ì—¬ì¤„ ìˆ˜ë„ ìˆìŒ
            md_text = f"# {source_name} ë³¸ë¬¸\n\n{md_text}"
        else:
            return []

        # ê³µí†µ í´ë¦¬ë‹
        md_text = clean_markdown_text(md_text)
        
        # êµ¬ì¡°í™” (ì œNì¡°, ë³„í‘œ ë“±ì„ í—¤ë”ë¡œ ë³€í™˜ - ì •ê·œì‹)
        md_text = re.sub(r'(^|\n)(ì œ\s*\d+(?:ì˜\d+)?\s*ì¡°)', r'\1# \2', md_text)
        md_text = re.sub(r'(^|\n)(\[ë³„í‘œ\s*\d+.*?\])', r'\1# \2', md_text)
        md_text = re.sub(r'(^|\n)(\[ë³„ì§€\s*.*?\])', r'\1# \2', md_text)

        # 1ë‹¨ê³„: í—¤ë” ê¸°ë°˜ ë¶„í• 
        headers_to_split_on = [("#", "Article_Title")]
        markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
        header_splits = markdown_splitter.split_text(md_text)
        
        # 2ë‹¨ê³„: ì¬ê·€ì  ë¬¸ì ë¶„í•  (ì„¸ë¶€ ì²­í‚¹)
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        
        final_docs = []
        for doc in header_splits:
            splits = text_splitter.split_text(doc.page_content)
            for split_content in splits:
                new_doc = Document(
                    page_content=split_content,
                    metadata={
                        "source": source_name,
                        "Article_Title": doc.metadata.get("Article_Title", "ì¼ë°˜"),
                        "file_type": file_ext
                    }
                )
                final_docs.append(new_doc)
                
        return final_docs
        
    finally:
        os.remove(tmp_path)

# --------------------------------------------------------------------------------
# 2. ì‚¬ì´ë“œë°” (ì„¤ì •)
# --------------------------------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    CUSTOM_MODELS = ["korean-llama3", "korean-gemma2"] 
    selected_model = st.selectbox("AI ëª¨ë¸ ì„ íƒ", CUSTOM_MODELS, index=0)

    st.markdown("---")
    st.header("ğŸ“‚ ë¬¸ì„œ ì—…ë¡œë“œ")
    # [ìˆ˜ì •] docx, hwp ë“± ë‹¤ì–‘í•œ í™•ì¥ì í—ˆìš©
    uploaded_files = st.file_uploader(
        "ê·œì • íŒŒì¼ (PDF, Word ê¶Œì¥)", 
        type=["pdf", "docx", "hwp"], 
        accept_multiple_files=True
    )
    if uploaded_files:
        st.caption("ğŸ’¡ Tip: í‘œê°€ í¬í•¨ëœ ê·œì •ì€ **Word(.docx)** íŒŒì¼ì´ ê°€ì¥ ì •í™•í•©ë‹ˆë‹¤.")

    process_button = st.button("ğŸš€ ê·œì • í•™ìŠµ ì‹œì‘")

    st.markdown("---")
    st.header("ğŸ“š ë“±ë¡ëœ ê·œì • ëª©ë¡")
    if 'learned_files' not in st.session_state:
        st.session_state.learned_files = []
        
    if st.session_state.learned_files:
        for f_name in st.session_state.learned_files:
            st.success(f"â€¢ {f_name}")
    else:
        st.info("ë“±ë¡ëœ ê·œì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” (rm -rf)"):
        st.session_state.clear() 
        try:
            if os.path.exists(PERSIST_DIRECTORY):
                shutil.rmtree(PERSIST_DIRECTORY)
                st.session_state.learned_files = [] # ëª©ë¡ ì¦‰ì‹œ ì´ˆê¸°í™”
                st.success("âœ… DB ì‚­ì œ ì™„ë£Œ! F5ë¥¼ ëˆŒëŸ¬ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
            else:
                st.info("ì‚­ì œí•  DBê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âš ï¸ íŒŒì¼ ì‚¬ìš© ì¤‘ ì˜¤ë¥˜: {e}")

# --------------------------------------------------------------------------------
# 3. ì„ë² ë”© ë° DB ì²˜ë¦¬
# --------------------------------------------------------------------------------
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

if uploaded_files and process_button:
    with st.spinner("ë‹¤ì–‘í•œ ë¬¸ì„œ í¬ë§· ë³€í™˜ ë° ì •ë°€ í•™ìŠµ ì¤‘..."):
        all_docs = []
        for file in uploaded_files:
            try:
                # [ìˆ˜ì •] íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ (PDF/DOCX/HWP ë¶„ê¸° ì²˜ë¦¬)
                docs = process_file_to_docs(file, file.name)
                all_docs.extend(docs)
            except Exception as e:
                st.error(f"'{file.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        if all_docs:
            vectorstore = Chroma(
                persist_directory=PERSIST_DIRECTORY,
                embedding_function=get_embeddings()
            )
            vectorstore.add_documents(all_docs)
            st.success(f"âœ… ì´ {len(all_docs)}ê°œì˜ ì²­í¬ê°€ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            for file in uploaded_files:
                if file.name not in st.session_state.learned_files:
                    st.session_state.learned_files.append(file.name)
            
            time.sleep(1)
            st.rerun()

# --------------------------------------------------------------------------------
# 4. ê²€ìƒ‰ ë° ë‹µë³€ ë¡œì§
# --------------------------------------------------------------------------------
embeddings = get_embeddings()
vectorstore = None
ensemble_retriever = None

if os.path.exists(PERSIST_DIRECTORY):
    try:
        vectorstore = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)
        chroma_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
        
        doc_data = vectorstore.get()
        if doc_data['documents']:
            bm25_docs = [Document(page_content=t, metadata=m) for t, m in zip(doc_data['documents'], doc_data['metadatas'])]
            bm25_retriever = BM25Retriever.from_documents(bm25_docs)
            bm25_retriever.k = 10
            
            ensemble_retriever = EnsembleRetriever(
                retrievers=[bm25_retriever, chroma_retriever],
                weights=[0.5, 0.5]
            )
        else:
            ensemble_retriever = chroma_retriever
            
    except ChromaInternalError:
        st.error("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì ê¸ˆ ì˜¤ë¥˜: ì„œë²„ ì¬ì‹œì‘ í•„ìš”")
    except Exception as e:
        st.error(f"DB ë¡œë“œ ì˜¤ë¥˜: {e}")

# ì±„íŒ… UI
if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.write(m["content"])

if prompt := st.chat_input("ê·œì •ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    with st.chat_message("assistant"):
        if ensemble_retriever:
            llm = ChatOllama(
                model=selected_model, 
                base_url="http://127.0.0.1:11434",
                temperature=0,
                top_p=0.1
            )
            
            # ì¤‘ë³µ ì œê±° ë¡œì§
            retrieved_docs = ensemble_retriever.invoke(prompt)
            unique_docs = []
            seen_content = set()
            for doc in retrieved_docs:
                content_snippet = doc.page_content[:100] 
                if content_snippet not in seen_content:
                    unique_docs.append(doc)
                    seen_content.add(content_snippet)
            final_context_docs = unique_docs[:5]
            context_text = "\n\n".join([doc.page_content for doc in final_context_docs])

            # [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ ê°„ì†Œí™” (ì œì•½ì¡°ê±´ ì¶œë ¥ ê¸ˆì§€)
            template = """
            [System Instruction]
            ë‹¹ì‹ ì€ íšŒì‚¬ ê·œì • ì „ë¬¸ AIì…ë‹ˆë‹¤. ì•„ë˜ [Context]ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”.
            ì‚¬ìš©ìê°€ ì½ê¸° í¸í•˜ê²Œ ë°”ë¡œ ê²°ë¡ ë¶€í„° ë‹µë³€í•˜ì„¸ìš”. 
            "ì œì•½ ì¡°ê±´ì„ ì¤€ìˆ˜í–ˆìŠµë‹ˆë‹¤" ê°™ì€ ë¶ˆí•„ìš”í•œ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”.

            [Context]:
            {context}

            [Question]:
            {question}

            ë‹µë³€(í•œêµ­ì–´):
            """
            
            prompt_obj = PromptTemplate(
                input_variables=["context", "question"],
                template=template
            )
            formatted_prompt = prompt_obj.format(context=context_text, question=prompt)
            
            try:
                with st.spinner("ì •ë°€ ë¶„ì„ ì¤‘..."):
                    response = llm.invoke(formatted_prompt).content
                
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                with st.expander("ì°¸ê³ í•œ ê·œì • ì›ë¬¸"):
                    for i, doc in enumerate(final_context_docs):
                         title = doc.metadata.get("Article_Title", "ì¡°í•­/ë³„í‘œ")
                         source = doc.metadata.get("source", "íŒŒì¼")
                         st.markdown(f"**[ì°¸ê³  {i+1}: {source} - {title}]**")
                         st.text(doc.page_content[:200] + "...")

            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {e}")
        else:
            st.warning("ë¬¸ì„œë¥¼ ë¨¼ì € í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")